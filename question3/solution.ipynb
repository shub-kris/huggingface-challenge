{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3: Include numerical/categorical data with a language model\n",
    "\n",
    "Hello Hugging Face! I have been using transformers to gauge whether product reviews are\n",
    "good or bad and so far, I have gotten decent results. I have information about how many\n",
    "products the user has purchased in the past, how many times users spend looking at that\n",
    "review, and a few other variables. Can we combine both the textual data with the numerical and\n",
    "categorical data? Can you provide an example of how this could be done? I have a feeling that\n",
    "this might produce the best results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Download the packages\n",
    "! pip install transformers datasets torch numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset, ClassLabel\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example data\n",
    "data = {\n",
    "    'reviews': [\"This product is great!\", \"Not satisfied with this product.\"],\n",
    "    'number_of_products': [3, 1],\n",
    "    'number_of_times': [5, 2],\n",
    "    'type_of_product': [\"Jeans\", \"Shirts\"]\n",
    "}\n",
    "\n",
    "dataset = Dataset.from_dict(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solutions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Approach 1: Concatenating numerical and categorical data as string with textual data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine numerical and categorical data as text\n",
    "def combine_data(row):\n",
    "    return {'concat_review': (\n",
    "        f\"This user has purchased {row['number_of_products']} products. \"\n",
    "        f\"This review was viewed {row['number_of_times']} times. \"\n",
    "        f\"The product that has been reviewed belongs to the category {row['type_of_product']}. \"\n",
    "        f\"Review of the product: {row['reviews']}\"\n",
    "    )}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 2/2 [00:00<00:00, 174.38 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This user has purchased 3 products. This review was viewed 5 times. The product that has been reviewed belongs to the category Jeans. Review of the product: This product is great!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Map the combine_data function to the dataset\n",
    "dataset = dataset.map(combine_data, remove_columns=['reviews', 'number_of_products', 'number_of_times', 'type_of_product'])\n",
    "print(dataset['concat_review'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Approach 2: Concatenating numerical and categorical features with textual features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example data\n",
    "data = {\n",
    "    'reviews': [\"This product is great!\", \"Not satisfied with this product.\"],\n",
    "    'number_of_products': [3, 1],\n",
    "    'number_of_times': [5, 2],\n",
    "    'type_of_product': [\"Jeans\", \"Shirts\"]\n",
    "}\n",
    "\n",
    "dataset = Dataset.from_dict(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModel.from_pretrained(\"distilbert-base-uncased\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "product_types = {product: idx for idx, product in enumerate(dataset['type_of_product'])} # map product types to integers\n",
    "num_classes = 2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenization(row):\n",
    "    return tokenizer(row[\"reviews\"], padding=True, max_length=10)\n",
    "\n",
    "def extract_numerical_features(row):\n",
    "    return {'num_feature': [row['number_of_products'], row['number_of_times']]}\n",
    "\n",
    "\n",
    "def extract_categorical_features(row):\n",
    "    cat_features = np.zeros(num_classes, dtype=int, )  # Initialize with zeros\n",
    "    cat_features[product_types[row['type_of_product']]] = 1\n",
    "    return {'cat_feature': cat_features}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 2/2 [00:00<00:00, 231.40 examples/s]\n",
      "Map: 100%|██████████| 2/2 [00:00<00:00, 182.29 examples/s]\n",
      "Map:   0%|          | 0/2 [00:00<?, ? examples/s]/Users/shubhamkrishna/.pyenv/versions/3.9.15/envs/hf-env/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:2436: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n",
      "Map: 100%|██████████| 2/2 [00:00<00:00, 32.17 examples/s]\n"
     ]
    }
   ],
   "source": [
    "new_dataset = dataset.map(extract_numerical_features, remove_columns=['number_of_products', 'number_of_times'])\n",
    "new_dataset = new_dataset.map(extract_categorical_features, remove_columns=['type_of_product'])\n",
    "new_dataset = new_dataset.map(tokenization, remove_columns=['reviews'], batched=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReviewClassifierModel(torch.nn.Module):\n",
    "    def __init__(self, model, cat_num_dims, num_classes):\n",
    "        \"\"\"\n",
    "        Initialize the ReviewClassifierModel.\n",
    "\n",
    "        Args:\n",
    "            model_name (str): The name of the pre-trained transformer model.\n",
    "            cat_num_dims (int): The number of dimensions summed from numerical and categorical data.\n",
    "            num_classes (int): The number of output classes.\n",
    "\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        # Load the model configuration and transformer\n",
    "        self.model = model\n",
    "\n",
    "        # Get the text embedding dimension\n",
    "        text_dim = self.model.config.hidden_size\n",
    "\n",
    "        # Create a linear classifier layer\n",
    "        self.classifier = torch.nn.Linear(text_dim + cat_num_dims, num_classes)\n",
    "\n",
    "    def forward(self, cat_num_vector, input_ids, attention_mask=None):\n",
    "        \"\"\"\n",
    "        Forward pass of the model.\n",
    "\n",
    "        Args:\n",
    "            input_ids (torch.Tensor): Input token IDs.\n",
    "            extra_data (torch.Tensor): Additional numerical/categorical data.\n",
    "            attention_mask (torch.Tensor, optional): Attention mask.\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: Model logits.\n",
    "\n",
    "        \"\"\"\n",
    "        # Pass input through the transformer for \n",
    "        hidden_states = self.model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "\n",
    "        # Extract the [CLS] token embeddings\n",
    "        cls_embeds = hidden_states.last_hidden_state[:, 0, :]\n",
    "        \n",
    "        # Concatenate transformer output with categorical and numerical features\n",
    "        concat = torch.cat((cls_embeds, cat_num_vector), dim=-1)\n",
    "\n",
    "        # Pass through the classifier\n",
    "        output = self.classifier(concat)\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_dataset = new_dataset.with_format(\"torch\")\n",
    "review_classifier = ReviewClassifierModel(model, cat_num_dims=2+2, num_classes=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 768])\n",
      "torch.Size([2, 4])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.2992, -0.0446],\n",
       "        [ 0.2632,  0.0151]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_num_feature = torch.concat((new_dataset['num_feature'], new_dataset['cat_feature']), dim=-1)\n",
    "review_classifier(cat_num_feature, new_dataset['input_ids'], new_dataset['attention_mask'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hf-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
